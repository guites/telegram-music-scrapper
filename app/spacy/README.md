# Train a custom NER with spaCy

This is a POC on how to train a custom named entity recognition model using spaCy and the data generated by the API.

The main file is `docbin_innit.py` which gets data from the API `/telegram_messages/artists` endpoint and converts it to spacy's docbin format, used to train the models.

## Install spaCy

Follow instructions from [the spaCy installation page](https://spacy.io/usage).

## Create the base_config.cfg file

Go to [the spaCy quickstart page](https://spacy.io/usage/training#quickstart) and generate a default config using the following options:

1. Language: English
2. Components: [x] ner
3. Hardware: CPU (or GPU if you have one available)
4. Optimize for: efficiency

Save the contents as `base_config.cfg`.

## Generate the config.cfg file

Now you can run

    python -m spacy init fill-config base_config.cfg config.cfg

To fill the configuration file with the necessary defaults. It will be save as `config.cfg` in the current directory.

## Generate the dataset

After setting up the configurations, run

    python3 docbin_innit.py

To convert the dataset to spacy's docbin format.

Running the command should result in a `training_data_{%d_%m_%Y}.spacy` file.

## Visualize the dataset

You can run

    python3 doc_viz.py

And access <http://localhost:5000> to visualize a sample of 30 annotated texts from the dataset.

## Train the model

You can now train the model using

    TRAINING_DATA=$(ls -lt training_data* | rev | head -n1 | cut -d' ' -f 1 | rev) \
    OUTPUT_DIR="${TRAINING_DATA%.*}" \
    python3 -m spacy train config.cfg --output "./model_$OUTPUT_DIR" --paths.train "./$TRAINING_DATA" --paths.dev "./$TRAINING_DATA"

append `--gpu-id 0` with your gpu id if you have one available.

This should result in a `model-best` and a `model-last` directory inside $OUTPUT_DIR.

## Evaluate the model

After creating your model, you can run the `evaluate.py` to test whether the model is producing good results.

    python3 evaluate.py "{MUSIC_NAME}" -d

substitute {MUSIC_NAME} with the text you want to run predictions on.

A displaCy instance will be started at <http://localhost:5000> showing predictions.
